{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzc/Common/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spammer_order = \"../data/spammer_order.csv\"\n",
    "feat_list = ['post_num', 'follower_num', 'followee_num', 'content_similar',\n",
    " 'figure_jing', 'figure_url', 'figure_face', 'figure_RRT', 'figure_face_every',\n",
    " 'figure_jing_every', 'figure_url_every', 'figure_url_single', 'figure_jing_single',\n",
    " 'figure_at', 'figure_at_every', 'figure_at_single', 'average_repost', 'average_comm',\n",
    " 'late_night_times', 'is_regular', 'shorttime_times', 'active_day_ratio', 'day_interval_variance',\n",
    " 'day_in_variance', 'follow_ratio']\n",
    "\n",
    "raw_file = pd.read_csv(spammer_order)\n",
    "data = raw_file[feat_list]\n",
    "target = raw_file[['is_spammer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_num</th>\n",
       "      <th>follower_num</th>\n",
       "      <th>followee_num</th>\n",
       "      <th>content_similar</th>\n",
       "      <th>figure_jing</th>\n",
       "      <th>figure_url</th>\n",
       "      <th>figure_face</th>\n",
       "      <th>figure_RRT</th>\n",
       "      <th>figure_face_every</th>\n",
       "      <th>figure_jing_every</th>\n",
       "      <th>...</th>\n",
       "      <th>figure_at_single</th>\n",
       "      <th>average_repost</th>\n",
       "      <th>average_comm</th>\n",
       "      <th>late_night_times</th>\n",
       "      <th>is_regular</th>\n",
       "      <th>shorttime_times</th>\n",
       "      <th>active_day_ratio</th>\n",
       "      <th>day_interval_variance</th>\n",
       "      <th>day_in_variance</th>\n",
       "      <th>follow_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15809</td>\n",
       "      <td>84</td>\n",
       "      <td>235</td>\n",
       "      <td>6</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.151</td>\n",
       "      <td>2.79762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11248</td>\n",
       "      <td>595</td>\n",
       "      <td>1533</td>\n",
       "      <td>40</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.082</td>\n",
       "      <td>2.57647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10069</td>\n",
       "      <td>450</td>\n",
       "      <td>1909</td>\n",
       "      <td>179</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.077</td>\n",
       "      <td>4.24222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8078</td>\n",
       "      <td>168</td>\n",
       "      <td>1907</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.099</td>\n",
       "      <td>11.35119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7389</td>\n",
       "      <td>173</td>\n",
       "      <td>1933</td>\n",
       "      <td>114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.057</td>\n",
       "      <td>11.17341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6462</td>\n",
       "      <td>373</td>\n",
       "      <td>1144</td>\n",
       "      <td>7</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.141</td>\n",
       "      <td>3.06702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6215</td>\n",
       "      <td>146</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.345</td>\n",
       "      <td>2.10959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6121</td>\n",
       "      <td>1172</td>\n",
       "      <td>1764</td>\n",
       "      <td>177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.164</td>\n",
       "      <td>1.50512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4836</td>\n",
       "      <td>528</td>\n",
       "      <td>931</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.096</td>\n",
       "      <td>1.76326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4807</td>\n",
       "      <td>467</td>\n",
       "      <td>663</td>\n",
       "      <td>42</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.109</td>\n",
       "      <td>1.41970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4752</td>\n",
       "      <td>489</td>\n",
       "      <td>704</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.43967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4732</td>\n",
       "      <td>522</td>\n",
       "      <td>686</td>\n",
       "      <td>30</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.079</td>\n",
       "      <td>1.31418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4639</td>\n",
       "      <td>468</td>\n",
       "      <td>1293</td>\n",
       "      <td>44</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.060</td>\n",
       "      <td>2.76282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4626</td>\n",
       "      <td>148</td>\n",
       "      <td>915</td>\n",
       "      <td>114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.115</td>\n",
       "      <td>6.18243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4531</td>\n",
       "      <td>502</td>\n",
       "      <td>1092</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.955</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.077</td>\n",
       "      <td>2.17530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4514</td>\n",
       "      <td>469</td>\n",
       "      <td>686</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.068</td>\n",
       "      <td>1.46269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4416</td>\n",
       "      <td>2080</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.94471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4353</td>\n",
       "      <td>127</td>\n",
       "      <td>320</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.286</td>\n",
       "      <td>2.51968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4342</td>\n",
       "      <td>572</td>\n",
       "      <td>928</td>\n",
       "      <td>34</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.059</td>\n",
       "      <td>1.62238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3999</td>\n",
       "      <td>501</td>\n",
       "      <td>993</td>\n",
       "      <td>35</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.905</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.063</td>\n",
       "      <td>1.98204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3942</td>\n",
       "      <td>597</td>\n",
       "      <td>890</td>\n",
       "      <td>19</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.129</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.130</td>\n",
       "      <td>1.49079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3854</td>\n",
       "      <td>101</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.026</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.215</td>\n",
       "      <td>2.38614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3837</td>\n",
       "      <td>1121</td>\n",
       "      <td>1043</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.93042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3774</td>\n",
       "      <td>155</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.164</td>\n",
       "      <td>5.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3586</td>\n",
       "      <td>161</td>\n",
       "      <td>487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>8.483</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.247</td>\n",
       "      <td>3.02485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3503</td>\n",
       "      <td>423</td>\n",
       "      <td>1983</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.129</td>\n",
       "      <td>4.68794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3444</td>\n",
       "      <td>467</td>\n",
       "      <td>1504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.103</td>\n",
       "      <td>3.22056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3411</td>\n",
       "      <td>78</td>\n",
       "      <td>1993</td>\n",
       "      <td>348</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.933</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.051</td>\n",
       "      <td>25.55128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3213</td>\n",
       "      <td>93</td>\n",
       "      <td>1782</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.042</td>\n",
       "      <td>19.16129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3173</td>\n",
       "      <td>384</td>\n",
       "      <td>1022</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.080</td>\n",
       "      <td>2.66146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>226</td>\n",
       "      <td>69</td>\n",
       "      <td>293</td>\n",
       "      <td>2</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.137</td>\n",
       "      <td>4.24638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>226</td>\n",
       "      <td>1106</td>\n",
       "      <td>963</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.134</td>\n",
       "      <td>7.229</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.87070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>226</td>\n",
       "      <td>433</td>\n",
       "      <td>816</td>\n",
       "      <td>2</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.203</td>\n",
       "      <td>1.88453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>225</td>\n",
       "      <td>250</td>\n",
       "      <td>407</td>\n",
       "      <td>7</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.62800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>225</td>\n",
       "      <td>2059</td>\n",
       "      <td>1923</td>\n",
       "      <td>3</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.93395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>224</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.74138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>224</td>\n",
       "      <td>426</td>\n",
       "      <td>1605</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>3.76761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>223</td>\n",
       "      <td>179</td>\n",
       "      <td>394</td>\n",
       "      <td>11</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.120</td>\n",
       "      <td>2.20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>222</td>\n",
       "      <td>125</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.23200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>222</td>\n",
       "      <td>115</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.430</td>\n",
       "      <td>1.743</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.99130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>222</td>\n",
       "      <td>60</td>\n",
       "      <td>231</td>\n",
       "      <td>5</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.231</td>\n",
       "      <td>3.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>222</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>14</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.139</td>\n",
       "      <td>1.69600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>222</td>\n",
       "      <td>36</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.332</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>222</td>\n",
       "      <td>1144</td>\n",
       "      <td>1068</td>\n",
       "      <td>19</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.93357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>221</td>\n",
       "      <td>29</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.164</td>\n",
       "      <td>3.62069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>221</td>\n",
       "      <td>94</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.159</td>\n",
       "      <td>1.10638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>221</td>\n",
       "      <td>49</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.142</td>\n",
       "      <td>2.22449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>221</td>\n",
       "      <td>198</td>\n",
       "      <td>291</td>\n",
       "      <td>3</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1.46970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>220</td>\n",
       "      <td>236</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.124</td>\n",
       "      <td>2.282</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.94068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>220</td>\n",
       "      <td>57</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.208</td>\n",
       "      <td>2.38597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>219</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.55172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>219</td>\n",
       "      <td>221</td>\n",
       "      <td>1479</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.121</td>\n",
       "      <td>6.69231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>218</td>\n",
       "      <td>60</td>\n",
       "      <td>288</td>\n",
       "      <td>3</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.200</td>\n",
       "      <td>4.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>218</td>\n",
       "      <td>185</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.261</td>\n",
       "      <td>1.139</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.16216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>217</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.162</td>\n",
       "      <td>1.07353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>216</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.127</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>215</td>\n",
       "      <td>174</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1.42529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>214</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.169</td>\n",
       "      <td>1.40741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>214</td>\n",
       "      <td>121</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.063</td>\n",
       "      <td>1.057</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.48760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>214</td>\n",
       "      <td>247</td>\n",
       "      <td>1702</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.134</td>\n",
       "      <td>6.89069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1716 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_num  follower_num  followee_num  content_similar  figure_jing  \\\n",
       "0        15809            84           235                6        0.168   \n",
       "1        11248           595          1533               40        0.011   \n",
       "2        10069           450          1909              179        0.000   \n",
       "3         8078           168          1907               38        0.000   \n",
       "4         7389           173          1933              114        0.000   \n",
       "5         6462           373          1144                7        0.138   \n",
       "6         6215           146           308                0        0.246   \n",
       "7         6121          1172          1764              177        0.000   \n",
       "8         4836           528           931               44        0.000   \n",
       "9         4807           467           663               42        0.012   \n",
       "10        4752           489           704               22        0.000   \n",
       "11        4732           522           686               30        0.006   \n",
       "12        4639           468          1293               44        0.006   \n",
       "13        4626           148           915              114        0.000   \n",
       "14        4531           502          1092               36        0.000   \n",
       "15        4514           469           686               43        0.000   \n",
       "16        4416          2080          1965                1        0.006   \n",
       "17        4353           127           320                5        0.217   \n",
       "18        4342           572           928               34        0.011   \n",
       "19        3999           501           993               35        0.006   \n",
       "20        3942           597           890               19        0.646   \n",
       "21        3854           101           241                1        0.046   \n",
       "22        3837          1121          1043                2        0.117   \n",
       "23        3774           155           837                0        0.000   \n",
       "24        3586           161           487                1        0.506   \n",
       "25        3503           423          1983                4        0.161   \n",
       "26        3444           467          1504                0        0.000   \n",
       "27        3411            78          1993              348        0.000   \n",
       "28        3213            93          1782               52        0.000   \n",
       "29        3173           384          1022               29        0.000   \n",
       "...        ...           ...           ...              ...          ...   \n",
       "1686       226            69           293                2        0.260   \n",
       "1687       226          1106           963                0        0.112   \n",
       "1688       226           433           816                2        0.057   \n",
       "1689       225           250           407                7        0.148   \n",
       "1690       225          2059          1923                3        0.011   \n",
       "1691       224            58            43                2        0.050   \n",
       "1692       224           426          1605                1        0.517   \n",
       "1693       223           179           394               11        0.258   \n",
       "1694       222           125            29                2        0.056   \n",
       "1695       222           115           229                0        0.140   \n",
       "1696       222            60           231                5        0.089   \n",
       "1697       222           125           212               14        0.309   \n",
       "1698       222            36            72                0        0.067   \n",
       "1699       222          1144          1068               19        0.489   \n",
       "1700       221            29           105                1        0.224   \n",
       "1701       221            94           104                2        0.466   \n",
       "1702       221            49           109                2        0.056   \n",
       "1703       221           198           291                3        0.111   \n",
       "1704       220           236           222                0        0.038   \n",
       "1705       220            57           136                2        0.078   \n",
       "1706       219            29            45                0        0.122   \n",
       "1707       219           221          1479                0        0.439   \n",
       "1708       218            60           288                3        0.237   \n",
       "1709       218           185           215                1        0.048   \n",
       "1710       217            68            73               11        0.018   \n",
       "1711       216            15            60                1        0.039   \n",
       "1712       215           174           248                3        0.105   \n",
       "1713       214            54            76                2        0.100   \n",
       "1714       214           121            59                0        0.051   \n",
       "1715       214           247          1702                0        0.483   \n",
       "\n",
       "      figure_url  figure_face  figure_RRT  figure_face_every  \\\n",
       "0          0.124        0.000       0.319              0.000   \n",
       "1          1.000        0.000       0.000              0.000   \n",
       "2          0.000        0.000       0.000              0.000   \n",
       "3          0.173        0.000       1.000              0.000   \n",
       "4          1.000        0.022       0.000              0.022   \n",
       "5          0.122        0.021       0.213              0.053   \n",
       "6          0.324        0.000       0.078              0.000   \n",
       "7          1.000        0.000       1.000              0.000   \n",
       "8          1.000        0.000       0.000              0.000   \n",
       "9          1.000        0.000       0.000              0.000   \n",
       "10         1.000        0.008       0.000              0.008   \n",
       "11         1.000        0.006       0.000              0.006   \n",
       "12         1.000        0.000       0.000              0.000   \n",
       "13         0.644        0.000       0.994              0.000   \n",
       "14         1.000        0.000       0.000              0.000   \n",
       "15         1.000        0.024       0.000              0.036   \n",
       "16         0.044        0.000       0.000              0.000   \n",
       "17         0.094        0.000       0.689              0.000   \n",
       "18         1.000        0.000       0.000              0.000   \n",
       "19         1.000        0.000       0.000              0.000   \n",
       "20         0.291        0.000       0.526              0.000   \n",
       "21         0.417        0.149       0.257              0.320   \n",
       "22         0.233        0.028       0.100              0.028   \n",
       "23         1.000        0.000       0.000              0.000   \n",
       "24         0.500        0.000       0.011              0.000   \n",
       "25         0.172        0.000       0.094              0.000   \n",
       "26         1.000        0.000       0.000              0.000   \n",
       "27         0.028        0.000       0.000              0.000   \n",
       "28         1.000        0.022       0.000              0.022   \n",
       "29         1.000        0.000       0.000              0.000   \n",
       "...          ...          ...         ...                ...   \n",
       "1686       0.220        0.000       0.011              0.000   \n",
       "1687       0.140        0.006       0.017              0.006   \n",
       "1688       0.038        0.038       0.089              0.038   \n",
       "1689       0.097        0.000       0.415              0.000   \n",
       "1690       0.006        0.006       0.000              0.006   \n",
       "1691       0.084        0.017       0.670              0.017   \n",
       "1692       0.202        0.000       0.522              0.000   \n",
       "1693       0.354        0.000       0.146              0.000   \n",
       "1694       0.051        0.006       0.023              0.006   \n",
       "1695       0.648        0.106       0.050              0.140   \n",
       "1696       0.028        0.000       0.928              0.000   \n",
       "1697       0.406        0.024       0.352              0.024   \n",
       "1698       0.117        0.111       0.678              0.194   \n",
       "1699       0.235        0.072       0.023              0.090   \n",
       "1700       0.121        0.024       0.776              0.024   \n",
       "1701       0.176        0.101       0.101              0.223   \n",
       "1702       0.095        0.106       0.006              0.128   \n",
       "1703       0.200        0.056       0.383              0.122   \n",
       "1704       0.115        0.105       0.019              0.167   \n",
       "1705       0.050        0.039       0.267              0.100   \n",
       "1706       0.061        0.044       0.828              0.072   \n",
       "1707       0.061        0.011       0.433              0.011   \n",
       "1708       0.209        0.000       0.186              0.000   \n",
       "1709       0.073        0.073       0.048              0.121   \n",
       "1710       0.848        0.000       0.049              0.000   \n",
       "1711       0.183        0.256       0.206              0.600   \n",
       "1712       0.370        0.037       0.426              0.056   \n",
       "1713       0.233        0.078       0.456              0.133   \n",
       "1714       0.040        0.103       0.080              0.240   \n",
       "1715       0.062        0.039       0.444              0.073   \n",
       "\n",
       "      figure_jing_every      ...       figure_at_single  average_repost  \\\n",
       "0                 0.200      ...                  0.065           0.005   \n",
       "1                 0.011      ...                  0.000           0.000   \n",
       "2                 0.000      ...                  0.000           0.000   \n",
       "3                 0.000      ...                  0.000           0.000   \n",
       "4                 0.000      ...                  0.000           0.004   \n",
       "5                 0.213      ...                  0.225           0.324   \n",
       "6                 0.279      ...                  0.074           0.363   \n",
       "7                 0.000      ...                  0.000           0.000   \n",
       "8                 0.000      ...                  0.000           0.000   \n",
       "9                 0.012      ...                  0.000           0.000   \n",
       "10                0.000      ...                  0.000           0.000   \n",
       "11                0.006      ...                  0.000           0.000   \n",
       "12                0.006      ...                  0.000           0.000   \n",
       "13                0.000      ...                  0.000           0.811   \n",
       "14                0.000      ...                  0.000           0.000   \n",
       "15                0.000      ...                  0.000           0.000   \n",
       "16                0.006      ...                  0.250           0.094   \n",
       "17                0.250      ...                  0.094           0.022   \n",
       "18                0.011      ...                  0.000           0.000   \n",
       "19                0.006      ...                  0.000           0.000   \n",
       "20                0.811      ...                  0.034           0.057   \n",
       "21                0.069      ...                  0.047           0.143   \n",
       "22                0.117      ...                  0.022           0.756   \n",
       "23                0.000      ...                  0.000           0.000   \n",
       "24                1.100      ...                  0.049           8.483   \n",
       "25                0.222      ...                  0.182           0.000   \n",
       "26                0.000      ...                  0.000           0.000   \n",
       "27                0.000      ...                  0.000           0.000   \n",
       "28                0.000      ...                  0.000           0.000   \n",
       "29                0.000      ...                  0.000           0.000   \n",
       "...                 ...      ...                    ...             ...   \n",
       "1686              0.322      ...                  0.162           0.096   \n",
       "1687              0.128      ...                  0.136           0.134   \n",
       "1688              0.064      ...                  0.242           0.357   \n",
       "1689              0.182      ...                  0.200           0.023   \n",
       "1690              0.017      ...                  0.200           0.737   \n",
       "1691              0.061      ...                  0.133           0.207   \n",
       "1692              0.708      ...                  0.027           0.017   \n",
       "1693              0.287      ...                  0.104           0.084   \n",
       "1694              0.056      ...                  0.308           0.627   \n",
       "1695              0.168      ...                  0.171           0.430   \n",
       "1696              0.094      ...                  0.250           0.000   \n",
       "1697              0.333      ...                  0.230           0.103   \n",
       "1698              0.067      ...                  0.230           0.017   \n",
       "1699              0.796      ...                  0.048           1.412   \n",
       "1700              0.248      ...                  0.373           0.006   \n",
       "1701              0.649      ...                  0.049           0.176   \n",
       "1702              0.061      ...                  0.312           0.000   \n",
       "1703              0.117      ...                  0.108           0.028   \n",
       "1704              0.048      ...                  0.117           0.124   \n",
       "1705              0.078      ...                  0.241           0.039   \n",
       "1706              0.156      ...                  0.065           0.022   \n",
       "1707              0.544      ...                  0.103           0.356   \n",
       "1708              0.243      ...                  0.078           0.130   \n",
       "1709              0.048      ...                  0.128           0.261   \n",
       "1710              0.018      ...                  0.182           0.091   \n",
       "1711              0.044      ...                  0.217           0.078   \n",
       "1712              0.160      ...                  0.098           0.148   \n",
       "1713              0.106      ...                  0.045           0.006   \n",
       "1714              0.057      ...                  0.147           0.063   \n",
       "1715              0.674      ...                  0.026           0.815   \n",
       "\n",
       "      average_comm  late_night_times  is_regular  shorttime_times  \\\n",
       "0            0.005             0.000           1                9   \n",
       "1            0.000             1.000           1                1   \n",
       "2            1.000             0.938           1                2   \n",
       "3            0.000             0.000           1                1   \n",
       "4            0.000             0.875           1                2   \n",
       "5            0.218             0.300           1                4   \n",
       "6            0.095             0.000           1                3   \n",
       "7            0.000             0.000           1                1   \n",
       "8            0.000             0.857           1                1   \n",
       "9            0.000             0.870           1                1   \n",
       "10           0.000             0.875           1                1   \n",
       "11           0.000             0.833           1                1   \n",
       "12           0.000             0.920           1                1   \n",
       "13           0.000             0.000           1                1   \n",
       "14           0.000             0.955           1                1   \n",
       "15           0.000             1.000           1                1   \n",
       "16           0.222             0.167           1                5   \n",
       "17           0.050             0.077           1               10   \n",
       "18           0.000             0.950           1                1   \n",
       "19           0.000             0.905           1                1   \n",
       "20           0.429             0.129           1                3   \n",
       "21           0.069             0.026           1                5   \n",
       "22           0.439             0.042           1                3   \n",
       "23           0.000             0.000           1                1   \n",
       "24           0.217             0.200           1               13   \n",
       "25           0.011             0.000           1                3   \n",
       "26           0.000             0.000           1                1   \n",
       "27           0.964             0.933           1                2   \n",
       "28           0.000             0.800           1                2   \n",
       "29           0.000             0.947           1                1   \n",
       "...            ...               ...         ...              ...   \n",
       "1686         0.672             0.000           0                2   \n",
       "1687         7.229             0.062           0                3   \n",
       "1688         0.357             0.000           0                8   \n",
       "1689         0.278             0.000           0                3   \n",
       "1690         0.631             0.000           0                1   \n",
       "1691         0.168             0.025           0                5   \n",
       "1692         0.393             0.025           0                2   \n",
       "1693         0.702             0.000           0                3   \n",
       "1694         0.655             0.455           0                2   \n",
       "1695         1.743             0.000           0                2   \n",
       "1696         0.022             0.000           0                5   \n",
       "1697         0.545             0.070           0                8   \n",
       "1698         0.083             0.000           0                7   \n",
       "1699         0.538             0.000           0                3   \n",
       "1700         0.006             0.016           0               11   \n",
       "1701         0.385             0.146           0                4   \n",
       "1702         0.687             0.000           0                3   \n",
       "1703         0.172             0.019           0                7   \n",
       "1704         2.282             0.089           0                6   \n",
       "1705         0.139             0.030           0               13   \n",
       "1706         0.028             0.026           0                4   \n",
       "1707         0.556             0.111           0                2   \n",
       "1708         0.169             0.008           0                3   \n",
       "1709         1.139             0.023           0                2   \n",
       "1710         0.079             0.029           0               12   \n",
       "1711         0.022             0.012           0                3   \n",
       "1712         0.426             0.011           0                4   \n",
       "1713         0.000             0.000           0                2   \n",
       "1714         1.057             0.014           0                2   \n",
       "1715         0.831             0.097           0                2   \n",
       "\n",
       "      active_day_ratio  day_interval_variance  day_in_variance  follow_ratio  \n",
       "0                1.000                  0.174            0.151       2.79762  \n",
       "1                0.933                  0.094            0.082       2.57647  \n",
       "2                0.941                  0.163            0.077       4.24222  \n",
       "3                0.857                  0.043            0.099      11.35119  \n",
       "4                0.889                  0.202            0.057      11.17341  \n",
       "5                0.909                  0.182            0.141       3.06702  \n",
       "6                0.800                  0.104            0.345       2.10959  \n",
       "7                0.667                  0.259            0.164       1.50512  \n",
       "8                1.000                  0.066            0.096       1.76326  \n",
       "9                0.920                  0.067            0.109       1.41970  \n",
       "10               0.889                  0.102            0.081       1.43967  \n",
       "11               0.960                  0.093            0.079       1.31418  \n",
       "12               0.926                  0.063            0.060       2.76282  \n",
       "13               1.000                  0.163            0.115       6.18243  \n",
       "14               1.000                  0.072            0.077       2.17530  \n",
       "15               0.875                  0.096            0.068       1.46269  \n",
       "16               0.857                  0.075            0.095       0.94471  \n",
       "17               1.000                  0.172            0.286       2.51968  \n",
       "18               0.952                  0.044            0.059       1.62238  \n",
       "19               1.000                  0.059            0.063       1.98204  \n",
       "20               0.096                  0.335            0.130       1.49079  \n",
       "21               0.514                  0.204            0.215       2.38614  \n",
       "22               0.032                  0.455            0.201       0.93042  \n",
       "23               1.000                  0.146            0.164       5.40000  \n",
       "24               1.000                  0.220            0.247       3.02485  \n",
       "25               0.846                  0.120            0.129       4.68794  \n",
       "26               0.750                  0.192            0.103       3.22056  \n",
       "27               0.375                  0.185            0.051      25.55128  \n",
       "28               0.278                  0.431            0.042      19.16129  \n",
       "29               0.864                  0.098            0.080       2.66146  \n",
       "...                ...                    ...              ...           ...  \n",
       "1686             0.161                  0.112            0.137       4.24638  \n",
       "1687             0.588                  0.090            0.117       0.87070  \n",
       "1688             0.621                  0.172            0.203       1.88453  \n",
       "1689             0.219                  0.089            0.200       1.62800  \n",
       "1690             0.982                  0.052            0.192       0.93395  \n",
       "1691             0.096                  0.149            0.276       0.74138  \n",
       "1692             0.138                  0.129            0.121       3.76761  \n",
       "1693             0.503                  0.102            0.120       2.20112  \n",
       "1694             0.230                  0.102            0.224       0.23200  \n",
       "1695             0.162                  0.082            0.160       1.99130  \n",
       "1696             0.500                  0.137            0.231       3.85000  \n",
       "1697             0.157                  0.133            0.139       1.69600  \n",
       "1698             0.564                  0.193            0.332       2.00000  \n",
       "1699             0.441                  0.116            0.143       0.93357  \n",
       "1700             0.299                  0.153            0.164       3.62069  \n",
       "1701             0.547                  0.140            0.159       1.10638  \n",
       "1702             0.144                  0.096            0.142       2.22449  \n",
       "1703             0.491                  0.149            0.173       1.46970  \n",
       "1704             0.233                  0.186            0.194       0.94068  \n",
       "1705             0.306                  0.230            0.208       2.38597  \n",
       "1706             0.549                  0.107            0.175       1.55172  \n",
       "1707             0.181                  0.167            0.121       6.69231  \n",
       "1708             0.131                  0.094            0.200       4.80000  \n",
       "1709             0.210                  0.088            0.174       1.16216  \n",
       "1710             0.093                  0.160            0.162       1.07353  \n",
       "1711             0.120                  0.133            0.127       4.00000  \n",
       "1712             0.080                  0.144            0.118       1.42529  \n",
       "1713             0.539                  0.073            0.169       1.40741  \n",
       "1714             0.172                  0.088            0.123       0.48760  \n",
       "1715             0.154                  0.131            0.134       6.89069  \n",
       "\n",
       "[1716 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split to train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    data, target, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_X.as_matrix()\n",
    "test_X = test_X.as_matrix()\n",
    "train_y = train_y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzc/Common/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/lzc/Common/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "gbm.fit(train_X, train_y)\n",
    "predictions = gbm.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86601942  0.87572816  0.88932039]\n",
      "Accuracy: 87.70% (0.96%)\n"
     ]
    }
   ],
   "source": [
    "# or use 10 fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# kfold = KFold(n_splits=7)\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "\n",
    "results = cross_val_score(model, data, target, cv=cv)\n",
    "print results\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "# initial mean accuracy 48.54%, deviation 31.44%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start adjusting the xgboost model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "    \n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('spammer_order.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_list = ['post_num', 'follower_num', 'followee_num', 'content_similar',\n",
    " 'figure_jing', 'figure_url', 'figure_face', 'figure_RRT', 'figure_face_every',\n",
    " 'figure_jing_every', 'figure_url_every', 'figure_url_single', 'figure_jing_single',\n",
    " 'figure_at', 'figure_at_every', 'figure_at_single', 'average_repost', 'average_comm',\n",
    " 'late_night_times', 'is_regular', 'shorttime_times', 'active_day_ratio', 'day_interval_variance',\n",
    " 'day_in_variance', 'follow_ratio']\n",
    "target='is_spammer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    858\n",
       "0    858\n",
       "Name: is_spammer, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[target] = data[target].map(dict(yes=1, no=0))\n",
    "data[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    xgb_param = alg.get_xgb_params()\n",
    "    xgtrain = xgb.DMatrix(dtrain[feat_list].values, label=dtrain[target].values)\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "        metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "    alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[feat_list], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[feat_list])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[feat_list])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(alg, data):\n",
    "#     kfold = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "    kfold = KFold(n_splits=10, random_state=0)\n",
    "    train = data[feat_list]\n",
    "    res = data[target]\n",
    "    scoring = ['accuracy', 'recall']\n",
    "    results = cross_val_score(alg, train, res, cv=kfold, scoring='accuracy')\n",
    "    print results\n",
    "    print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    # initial mean accuracy 48.54%, deviation 31.44%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find the number of estimators for a high learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.01162791  0.          0.\n",
      "  0.          0.          0.        ]\n",
      "Accuracy: 0.12% (0.35%)\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# cross_val(clf, data)\n",
    "\n",
    "modelfit(xgb1, data)\n",
    "\n",
    "# cross_val(xgb1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=0, test_size=0.3, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=140, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'max_depth': [3, 5, 7, 9], 'min_child_weight': [1, 3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                       param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=True, cv=shuffle)\n",
    "gsearch1.fit(data[feat_list],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzc/Common/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.94591, std: 0.00212, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.94554, std: 0.00283, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.94417, std: 0.00271, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.94577, std: 0.00338, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.94720, std: 0.00183, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.94416, std: 0.00354, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.94839, std: 0.00154, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.94558, std: 0.00106, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.94524, std: 0.00083, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.94772, std: 0.00051, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.94604, std: 0.00183, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.94419, std: 0.00188, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 7, 'min_child_weight': 1},\n",
       " 0.9483925885658111)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=2, missing=None, n_estimators=140, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'max_depth': [6, 7, 8], 'min_child_weight': [4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test2 = {\n",
    "    'max_depth':[6,7,8],\n",
    "    'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(data[feat_list],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.76303, std: 0.11195, params: {'max_depth': 6, 'min_child_weight': 4},\n",
       "  mean: 0.77081, std: 0.09711, params: {'max_depth': 6, 'min_child_weight': 5},\n",
       "  mean: 0.77529, std: 0.09582, params: {'max_depth': 6, 'min_child_weight': 6},\n",
       "  mean: 0.75858, std: 0.10624, params: {'max_depth': 7, 'min_child_weight': 4},\n",
       "  mean: 0.77117, std: 0.10915, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.78041, std: 0.09736, params: {'max_depth': 7, 'min_child_weight': 6},\n",
       "  mean: 0.75987, std: 0.10989, params: {'max_depth': 8, 'min_child_weight': 4},\n",
       "  mean: 0.76625, std: 0.10350, params: {'max_depth': 8, 'min_child_weight': 5},\n",
       "  mean: 0.76502, std: 0.10417, params: {'max_depth': 8, 'min_child_weight': 6}],\n",
       " {'max_depth': 7, 'min_child_weight': 6},\n",
       " 0.7804123012412337)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=2, missing=None, n_estimators=140, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'min_child_weight': [6, 8, 10, 12, 14, 16]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2b = {\n",
    "    'min_child_weight':[6,8,10,12, 14, 16]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=7,\n",
    "                                        min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test2b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2b.fit(data[feat_list],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.78041, std: 0.09736, params: {'min_child_weight': 6},\n",
       "  mean: 0.78582, std: 0.09375, params: {'min_child_weight': 8},\n",
       "  mean: 0.79661, std: 0.07896, params: {'min_child_weight': 10},\n",
       "  mean: 0.80972, std: 0.06539, params: {'min_child_weight': 12},\n",
       "  mean: 0.82104, std: 0.04935, params: {'min_child_weight': 14},\n",
       "  mean: 0.83822, std: 0.04270, params: {'min_child_weight': 16}],\n",
       " {'min_child_weight': 16},\n",
       " 0.8382241428808677)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=2, missing=None, n_estimators=140, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'min_child_weight': [16, 20, 24, 28, 32, 36, 40]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2c = {\n",
    "    'min_child_weight':[16, 20, 24, 28, 32, 36, 40]\n",
    "}\n",
    "gsearch2c = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=7,\n",
    "                                        min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test2c, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2c.fit(data[feat_list],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83822, std: 0.04270, params: {'min_child_weight': 16},\n",
       "  mean: 0.85044, std: 0.03144, params: {'min_child_weight': 20},\n",
       "  mean: 0.86194, std: 0.03041, params: {'min_child_weight': 24},\n",
       "  mean: 0.86878, std: 0.03064, params: {'min_child_weight': 28},\n",
       "  mean: 0.87156, std: 0.02665, params: {'min_child_weight': 32},\n",
       "  mean: 0.87476, std: 0.02708, params: {'min_child_weight': 36},\n",
       "  mean: 0.87476, std: 0.02559, params: {'min_child_weight': 40}],\n",
       " {'min_child_weight': 36},\n",
       " 0.8747646590430703)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2c.grid_scores_, gsearch2c.best_params_, gsearch2c.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=6, missing=None, n_estimators=140, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test3 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=4,\n",
    "                                        min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(data[feat_list],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.76872, std: 0.10037, params: {'gamma': 0.0},\n",
       "  mean: 0.77219, std: 0.10086, params: {'gamma': 0.1},\n",
       "  mean: 0.76760, std: 0.10067, params: {'gamma': 0.2},\n",
       "  mean: 0.76590, std: 0.10160, params: {'gamma': 0.3},\n",
       "  mean: 0.76757, std: 0.10231, params: {'gamma': 0.4}],\n",
       " {'gamma': 0.1},\n",
       " 0.7721892820668668)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81941748  0.86990291  0.82330097]\n",
      "Accuracy: 83.75% (2.29%)\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=7,\n",
    "        min_child_weight=36,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "# modelfit(xgb2, data)\n",
    "cross_val(xgb2, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.1, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=36, missing=None, n_estimators=177, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=7,\n",
    "                                        min_child_weight=36, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(data[feat_list],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.86950, std: 0.02939, params: {'subsample': 0.6, 'colsample_bytree': 0.6},\n",
       "  mean: 0.86900, std: 0.03143, params: {'subsample': 0.7, 'colsample_bytree': 0.6},\n",
       "  mean: 0.86873, std: 0.03514, params: {'subsample': 0.8, 'colsample_bytree': 0.6},\n",
       "  mean: 0.86805, std: 0.03126, params: {'subsample': 0.9, 'colsample_bytree': 0.6},\n",
       "  mean: 0.86560, std: 0.03055, params: {'subsample': 0.6, 'colsample_bytree': 0.7},\n",
       "  mean: 0.86970, std: 0.02942, params: {'subsample': 0.7, 'colsample_bytree': 0.7},\n",
       "  mean: 0.87064, std: 0.03040, params: {'subsample': 0.8, 'colsample_bytree': 0.7},\n",
       "  mean: 0.86570, std: 0.03226, params: {'subsample': 0.9, 'colsample_bytree': 0.7},\n",
       "  mean: 0.87144, std: 0.02966, params: {'subsample': 0.6, 'colsample_bytree': 0.8},\n",
       "  mean: 0.87274, std: 0.02856, params: {'subsample': 0.7, 'colsample_bytree': 0.8},\n",
       "  mean: 0.86649, std: 0.02999, params: {'subsample': 0.8, 'colsample_bytree': 0.8},\n",
       "  mean: 0.86459, std: 0.03378, params: {'subsample': 0.9, 'colsample_bytree': 0.8},\n",
       "  mean: 0.87028, std: 0.03209, params: {'subsample': 0.6, 'colsample_bytree': 0.9},\n",
       "  mean: 0.87092, std: 0.03058, params: {'subsample': 0.7, 'colsample_bytree': 0.9},\n",
       "  mean: 0.86672, std: 0.02991, params: {'subsample': 0.8, 'colsample_bytree': 0.9},\n",
       "  mean: 0.86356, std: 0.02951, params: {'subsample': 0.9, 'colsample_bytree': 0.9}],\n",
       " {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       " 0.8727419085040082)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.1, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=36, missing=None, n_estimators=177, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'reg_alpha': [1e-05, 0.01, 0.1, 1, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test6 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=7,\n",
    "                                        min_child_weight=36, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(data[feat_list],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.86649, std: 0.02999, params: {'reg_alpha': 1e-05},\n",
       "  mean: 0.86819, std: 0.03117, params: {'reg_alpha': 0.01},\n",
       "  mean: 0.86591, std: 0.02962, params: {'reg_alpha': 0.1},\n",
       "  mean: 0.86758, std: 0.02934, params: {'reg_alpha': 1},\n",
       "  mean: 0.85370, std: 0.02755, params: {'reg_alpha': 100}],\n",
       " {'reg_alpha': 0.01},\n",
       " 0.8681899913493742)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.1, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=36, missing=None, n_estimators=177, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'reg_alpha': [0, 0.001, 0.005, 0.01, 0.05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test7 = {\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=7,\n",
    "                                        min_child_weight=36, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(data[feat_list],data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.86649, std: 0.02999, params: {'reg_alpha': 0},\n",
       "  mean: 0.86650, std: 0.02999, params: {'reg_alpha': 0.001},\n",
       "  mean: 0.86790, std: 0.03099, params: {'reg_alpha': 0.005},\n",
       "  mean: 0.86819, std: 0.03117, params: {'reg_alpha': 0.01},\n",
       "  mean: 0.86789, std: 0.03002, params: {'reg_alpha': 0.05}],\n",
       " {'reg_alpha': 0.01},\n",
       " 0.8681899913493742)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.8741\n",
      "AUC Score (Train): 0.950296\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AxesSubplot' object has no attribute 'savefig'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2a9ca748915b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         seed=27)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodelfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-8b193ecc750c>\u001b[0m in \u001b[0;36mmodelfit\u001b[0;34m(alg, dtrain, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfeat_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mfeat_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Feature Importances'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature Importance Score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 'savefig'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAFsCAYAAADYJe9pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f24237450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=7,\n",
    "        min_child_weight=36,\n",
    "        gamma=0.1,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.01,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "modelfit(xgb3, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78682171  0.85130112  0.77777778]\n",
      "Accuracy: 80.53% (3.27%)\n"
     ]
    }
   ],
   "source": [
    "cross_val(xgb3, data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
