{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import etree\n",
    "import traceback\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log\n",
      "共10条微博\n",
      "信息抓取完毕\n",
      "===========================================================================\n",
      "用户名：Dear-迪丽热巴\n",
      "全部微博数：682\n",
      "关注数：183\n",
      "粉丝数：23709416\n",
      "最新一条微博为：跟大家介绍一下我的新宠 - 飘柔Micellar微米净透系列！现在买买买还有机会获得跟我同款的超美丝巾和手帐本哦！美美的@飘柔Rejoice 广告片也来啦，跟我一起享受头皮呼吸，头发柔顺的奢宠体验吧！  飘柔Rejoice微米净透系列 \n",
      "最新一条微博获得的点赞数：289011\n",
      "最新一条微博获得的转发数：16872\n",
      "最新一条微博获得的评论数：23143\n",
      "微博写入文件完毕，保存路径/home/wendell/git_wsl/SinaSpider\\weibo\\1669879400.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /usr/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import etree\n",
    "import traceback\n",
    "\n",
    "class weibo:\n",
    "    \n",
    "    #weibo类初始化\n",
    "    def __init__(self,user_id,filter = 0):\n",
    "            self.user_id = user_id #用户id，即需要我们输入的数字，如昵称为“Dear-迪丽热巴”的id为1669879400\n",
    "            self.filter = filter #取值范围为0、1，程序默认值为0，代表要爬取用户的全部微博，1代表只爬取用户的原创微博\n",
    "            self.userName = '' #用户名，如“Dear-迪丽热巴”\n",
    "            self.weiboNum = 0 #用户全部微博数\n",
    "            self.weiboNum2 = 0 #爬取到的微博数\n",
    "            self.following = 0 #用户关注数\n",
    "            self.followers = 0 #用户粉丝数\n",
    "            self.weibos = [] #微博内容\n",
    "            self.num_zan = [] #微博对应的点赞数\n",
    "            self.num_forwarding = [] #微博对应的转发数\n",
    "            self.num_comment = [] #微博对应的评论数\n",
    "            self.session = requests.session()\n",
    "            self.weibos_flag = []\n",
    "            self.headers2 = {\n",
    "                \"Accept\":\"*/*\",\n",
    "                \"Accept-Encoding\":\"gzip, deflate, br\",\n",
    "                \"Accept-Language\":\"en-US,en;q=0.8\",\n",
    "                \"Connection\":\"keep-alive\",\n",
    "                \"Content-Length\":\"184\",\n",
    "                \"Content-Type\":\"application/x-www-form-urlencoded\",\n",
    "                \"Host\":\"passport.weibo.cn\",\n",
    "                \"Origin\":\"https://passport.weibo.cn\",\n",
    "                \"Referer\":\"https://passport.weibo.cn/signin/login?entry=mweibo&r=http://weibo.cn/\",\n",
    "                \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36\"\n",
    "                }\n",
    "            self.headers3 = {\n",
    "                \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "                \"Accept-Encoding\":\"gzip, deflate, sdch, br\",\n",
    "                \"Accept-Language\":\"en-US,en;q=0.8\",\n",
    "                \"Connection\":\"keep-alive\",\n",
    "                \"Host\":\"weibo.cn\",\n",
    "                \"Upgrade-Insecure-Requests\":\"1\",\n",
    "                \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36\"\n",
    "                }\n",
    "            self.data = {\n",
    "                \"username\":\"727883459@qq.com\",\n",
    "                \"password\":\"weibo@q5.com\",\n",
    "                \"savestate\":\"1\",\n",
    "                \"r\":\"http://weibo.cn/\",\n",
    "                \"ec\":\"0\",\n",
    "                \"pagerefer\":\"\",\n",
    "                \"entry\":\"mweibo\",\n",
    "                \"wentry\":\"\",\n",
    "                \"loginfrom\":\"\",\n",
    "                \"client_id\":\"\",\n",
    "                \"code\":\"\",\n",
    "                \"qq\":\"\",\n",
    "                \"mainpageflag\":\"1\",\n",
    "                \"hff\":\"\",\n",
    "                \"hfp\":\"\"\n",
    "                }\n",
    "            self.time_list = []\n",
    "    #获取用户昵称     \n",
    "\n",
    "    def login(self):\n",
    "        \n",
    "        url = \"https://passport.weibo.cn/sso/login\"\n",
    "        cont = self.session.post(url,headers=self.headers2,data=self.data)\n",
    "        print (\"log\")\n",
    "\n",
    "    def getUserName(self):\n",
    "        try:\n",
    "            url = 'http://weibo.cn/%d/info'%(self.user_id)\n",
    "            html = self.session.get(url, headers=self.headers3).content\n",
    "            selector = etree.HTML(html)\n",
    "            userName = selector.xpath(\"//title/text()\")[0]\n",
    "            self.userName = userName[:-3].encode('gbk')\n",
    "            #print '用户昵称：' + self.userName\n",
    "        except Exception as e:        \n",
    "            print (\"Error: \",e) \n",
    "            traceback.print_exc()\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #获取用户微博数、关注数、粉丝数\n",
    "    def getUserInfo(self):\n",
    "      try:\n",
    "        url = 'http://weibo.cn/u/%d?filter=%d&page=1'%(self.user_id,self.filter)\n",
    "        html = self.session.get(url, headers=self.headers3).content\n",
    "#         with open(\"test.txt\",'wb') as filename:\n",
    "#             filename.write(html)\n",
    "        selector = etree.HTML(html)\n",
    "        pattern = r\"\\d+\\.?\\d*\"\n",
    "\n",
    "        #微博数\n",
    "        str_wb = selector.xpath(\"//div[@class='tip2']/span[@class='tc']/text()\")[0]\n",
    "        guid = re.findall(pattern, str_wb, re.S|re.M)   \n",
    "        for value in guid:   \n",
    "            num_wb = int(value)  \n",
    "            break\n",
    "        self.weiboNum = num_wb  \n",
    "        #print '微博数: ' + str(self.weiboNum) \n",
    "  \n",
    "        #关注数\n",
    "        str_gz = selector.xpath(\"//div[@class='tip2']/a/text()\")[0]\n",
    "        guid = re.findall(pattern, str_gz, re.M)  \n",
    "        self.following = int(guid[0])  \n",
    "        #print '关注数: ' + str(self.following)\n",
    "\n",
    "        #粉丝数\n",
    "        str_fs = selector.xpath(\"//div[@class='tip2']/a/text()\")[1]\n",
    "        guid = re.findall(pattern, str_fs, re.M)  \n",
    "        self.followers = int(guid[0]) \n",
    "        #print '粉丝数: ' + str(self.followers)\n",
    "      except Exception as e:        \n",
    "        print (\"Error: \",e)\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    #获取用户微博内容及对应的点赞数、转发数、评论数    \n",
    "    def getWeiboInfo(self):\n",
    "      try:\n",
    "        url = 'http://weibo.cn/u/%d?filter=%d&page=1'%(self.user_id,self.filter)\n",
    "        html = self.session.get(url, headers=self.headers3).content\n",
    "        selector = etree.HTML(html)        \n",
    "        if selector.xpath('//input[@name=\"mp\"]')==[]:\n",
    "           pageNum = 1\n",
    "        else:\n",
    "           pageNum = (int)(selector.xpath('//input[@name=\"mp\"]')[0].attrib['value'])\n",
    "        pattern = r\"\\d+\\.?\\d*\"\n",
    "#         for page in range(1,pageNum+1):\n",
    "        \n",
    "        for page in range(1,2):\n",
    "          url2 = 'http://weibo.cn/u/%d?filter=%d&page=%d'%(self.user_id,self.filter,page)\n",
    "          html2 = self.session.get(url2, headers=self.headers3).content\n",
    "          selector2 = etree.HTML(html2)\n",
    "          info = selector2.xpath(\"//div[@class='c']\")\n",
    "          soup = BeautifulSoup(html)\n",
    "          self.time_list =self.time_list + [x.string for x in  soup.find_all('span',class_='ct')]\n",
    "          #print len(info)\n",
    "          if len(info) > 3:\n",
    "            for i in range(0,len(info)-2):\n",
    "              self.weiboNum2 = self.weiboNum2 + 1\n",
    "              #微博内容\n",
    "              str_t = info[i].xpath(\"div/span[@class='ctt']\")\n",
    "              weibos = str_t[0].xpath('string(.)').encode('gbk','ignore')\n",
    "                \n",
    "              if len(info[i].xpath(\"div/span[@class='cmt']\")) !=0:\n",
    "                    self.weibos_flag.append(1)\n",
    "              else:\n",
    "                    self.weibos_flag.append(0)\n",
    "              self.weibos.append(weibos)\n",
    "              #print '微博内容：'+ weibos\n",
    "              #点赞数\n",
    "              str_zan = info[i].xpath(\"div/a/text()\")[-4]\n",
    "              guid = re.findall(pattern, str_zan, re.M)  \n",
    "              num_zan = int(guid[0])\n",
    "              self.num_zan.append(num_zan)\n",
    "              #print '点赞数: ' + str(num_zan)\n",
    "              #转发数\n",
    "              forwarding = info[i].xpath(\"div/a/text()\")[-3]\n",
    "              guid = re.findall(pattern, forwarding, re.M)  \n",
    "              num_forwarding = int(guid[0])\n",
    "              self.num_forwarding.append(num_forwarding)              \n",
    "              #print '转发数: ' + str(num_forwarding)\n",
    "              #评论数\n",
    "              comment = info[i].xpath(\"div/a/text()\")[-2]\n",
    "              guid = re.findall(pattern, comment, re.M)  \n",
    "              num_comment = int(guid[0]) \n",
    "              self.num_comment.append(num_comment)\n",
    "              #print '评论数: ' + str(num_comment)\n",
    "        if self.filter == 0:\n",
    "          print ('共'+str(self.weiboNum2)+'条微博')\n",
    "        else:\n",
    "          print (u'共'+str(self.weiboNum)+'条微博，其中'+str(self.weiboNum2)+'条为原创微博')\n",
    "      except Exception as e:        \n",
    "        print (\"Error: \",e)\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    #主程序\n",
    "    def start(self):\n",
    "      try:\n",
    "        weibo.login(self)\n",
    "        weibo.getUserName(self)\n",
    "        weibo.getUserInfo(self)\n",
    "        weibo.getWeiboInfo(self)\n",
    "        print ('信息抓取完毕')\n",
    "        print ('===========================================================================')\n",
    "      except Exception as e:        \n",
    "        print (\"Error: \",e)\n",
    "    \n",
    "    #将爬取的信息写入文件 \n",
    "    def writeTxt(self):\n",
    "      txt_dict = {}\n",
    "      try:\n",
    "        if self.filter == 1:\n",
    "            \n",
    "           resultHeader = '\\n\\n原创微博内容：\\n'\n",
    "        else:\n",
    "           resultHeader = '\\n\\n微博内容：\\n'\n",
    "        txt_dict['name'] =  self.userName.decode('gbk') #用户信息\n",
    "        txt_dict['id'] = str(self.user_id)   #用户id\n",
    "        txt_dict['weibos_num'] = str(self.weiboNum)   #微博数\n",
    "        txt_dict['following_num'] = str(self.following)  #关注数\n",
    "        txt_dict['followers_num'] = str(self.followers)   #粉丝数\n",
    "        txt_dict['weibo'] = []\n",
    "\n",
    "#         result = '用户信息\\n用户昵称：' + self.userName.decode('gbk') + '\\n用户id：' + str(self.user_id) + '\\n微博数：' + str(self.weiboNum) + '\\n关注数：' + str(self.following) + '\\n粉丝数：' + str(self.followers) + resultHeader\n",
    "        for i in range(1,self.weiboNum2 + 1):\n",
    "            weibo_dict = {}\n",
    "            weibo_dict['content'] = self.weibos[i-1].decode('gbk') #微博内容\n",
    "            weibo_dict['upvote'] = str(self.num_zan[i-1]) #点赞数\n",
    "            weibo_dict['forward'] = str(self.num_forwarding[i-1]) #转发数\n",
    "            weibo_dict['comment'] = str(self.num_comment[i-1])  #评论数\n",
    "            weibo_dict['time'] = self.time_list[i-1] #时间\n",
    "            weibo_dict['forward_flag'] = self.weibos_flag[i-1] #是否是转发\n",
    "            txt_dict['weibo'].append(weibo_dict)\n",
    "        \n",
    "#         text=str(i) + ':' + self.weibos[i-1].decode('gbk') + '\\n'+'点赞数：' + str(self.num_zan[i-1]) + '    转发数：' + str(self.num_forwarding[i-1]) + '   评论数：' + str(self.num_comment[i-1]) + '\\n'+self.time_list[i-1]+'\\n'+'转发:'+str(self.weibos_flag[i-1])+'\\n\\n'\n",
    "#         result = result + text\n",
    "                                        \n",
    "        result = json.dumps(txt_dict,sort_keys=True, indent=4,ensure_ascii=False)                           \n",
    "        if os.path.isdir('weibo') == False:\n",
    "           os.mkdir('weibo')\n",
    "    \n",
    "        f = open(\"weibo/%s.txt\"%self.user_id, \"w\",encoding='utf-8')\n",
    "        f.write(result)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "        file_path=os.getcwd()+\"\\weibo\"+\"\\%d\"%self.user_id+\".txt\"\n",
    "        print ('微博写入文件完毕，保存路径%s'%(file_path))\n",
    "      except Exception as e:        \n",
    "        print (\"Error: \",e )\n",
    "        traceback.print_exc()       \n",
    "        \n",
    "\n",
    "def spider_run(user_id):\n",
    "    #可以改成任意合法的用户id（爬虫的微博id除外）\n",
    "    filter = 0 #值为0表示爬取全部的微博信息（原创微博+转发微博），值为1表示只爬取原创微博\n",
    "    wb = weibo(user_id,filter) #调用weibo类，创建微博实例wb\n",
    "    wb.start() #爬取微博信息\n",
    "    print ('用户名：' + wb.userName.decode('gbk'))\n",
    "    print('id:'+user_id)\n",
    "    print ('全部微博数：' + str(wb.weiboNum))\n",
    "    print ('关注数：' + str(wb.following))\n",
    "    print ('粉丝数：' + str(wb.followers))\n",
    "    print ('最新一条微博为：' + wb.weibos[0].decode('gbk') )#若filter=1则为最新的原创微博，如果该用户微博数为0，即len(wb.weibos)==0,打印会出错，下同\n",
    "    print ('最新一条微博获得的点赞数：' + str(wb.num_zan[0]))\n",
    "    print ('最新一条微博获得的转发数：' + str(wb.num_forwarding[0]))\n",
    "    print ('最新一条微博获得的评论数：' + str(wb.num_comment[0]))\n",
    "    wb.writeTxt() #wb.writeTxt()只是把信息写到文件里，大家可以根据自己的需要重新编写writeTxt()函数\n",
    "\n",
    "    \n",
    "spider_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear-迪丽热巴\n",
      "183\n",
      "跟大家介绍一下我的新宠 - 飘柔Micellar微米净透系列！现在买买买还有机会获得跟我同款的超美丝巾和手帐本哦！美美的@飘柔Rejoice 广告片也来啦，跟我一起享受头皮呼吸，头发柔顺的奢宠体验吧！  飘柔Rejoice微米净透系列 \n"
     ]
    }
   ],
   "source": [
    "print( wb.userName.decode('gbk'))\n",
    "print (wb.following)\n",
    "print (wb.weibos[0].decode('gbk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-85dde441e724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/user_post.xls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "user_post = pd.read_excel('./data/user_post.xls', 'user_post')[list(range(9))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pandas import Series,DataFrame\n",
    "import jieba\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import gensim\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import codecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_post = pd.read_excel('./data/spammer_order.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2065072254\n",
      "1       3753444374\n",
      "2       3800925698\n",
      "3       3938859131\n",
      "4       3278184025\n",
      "5       5035867320\n",
      "6       1495710180\n",
      "7       2668003111\n",
      "8       5014697929\n",
      "9       3941665298\n",
      "10      5032866773\n",
      "11      5032833233\n",
      "12      5028636903\n",
      "13      5088923657\n",
      "14      5032807933\n",
      "15      5032737101\n",
      "16      1200860993\n",
      "17      3172808350\n",
      "18      5035346498\n",
      "19      5036284104\n",
      "20      3308626032\n",
      "21      3850432914\n",
      "22      2102882751\n",
      "23      3903486165\n",
      "24      2161663171\n",
      "25      2702681951\n",
      "26      5061547563\n",
      "27      5204123253\n",
      "28      5219339446\n",
      "29      5042018968\n",
      "           ...    \n",
      "1686    3204536992\n",
      "1687    5044708847\n",
      "1688    5345592399\n",
      "1689    3292997991\n",
      "1690    5332299881\n",
      "1691    2874845130\n",
      "1692    3116599705\n",
      "1693    3527941355\n",
      "1694    1906728683\n",
      "1695    2023316472\n",
      "1696    2284855403\n",
      "1697    2938953721\n",
      "1698    3170595722\n",
      "1699    3238522320\n",
      "1700    2021613797\n",
      "1701    2792603361\n",
      "1702    2868301724\n",
      "1703    3544398101\n",
      "1704    5119063117\n",
      "1705    5199699592\n",
      "1706    2924089352\n",
      "1707    3182526290\n",
      "1708    2733601982\n",
      "1709    3097525517\n",
      "1710    1867324394\n",
      "1711    2787868041\n",
      "1712    2457657800\n",
      "1713    1254525744\n",
      "1714    2600471551\n",
      "1715    3109399257\n",
      "Name: user_id, Length: 1716, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(user_post['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.ipynb_checkpoints', 'README.md', 'SourceHanSans-Regular.otf', 'XGBoost-models.ipynb', 'data', 'networkx_test.ipynb', 'pro.ipynb', 'spider', 'tmp.png', 'user_post', 'user_post_process_wendell.ipynb', 'weiboSpider.ipynb', 'word_cut.ipynb', 'words_in_post.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "print (os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
